{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158322b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f48733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('news.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1263ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>4490</td>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>8062</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>8622</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>4021</td>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>4330</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "0           8476                       You Can Smell Hillary’s Fear   \n",
       "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4            875   The Battle of New York: Why This Primary Matters   \n",
       "...          ...                                                ...   \n",
       "6330        4490  State Department says it can't find emails fro...   \n",
       "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd749043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0e9d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          You Can Smell Hillary’s Fear   \n",
       "1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           Kerry to go to Paris in gesture of sympathy   \n",
       "3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "4      The Battle of New York: Why This Primary Matters   \n",
       "...                                                 ...   \n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7554e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53e9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5bf2b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 26381)\t-0.07738232325341368\n",
      "  (1, 46353)\t0.07738232325341368\n",
      "  (1, 68115)\t0.07738232325341368\n",
      "  (1, 76282)\t-0.07738232325341368\n",
      "  (1, 81635)\t-0.07738232325341368\n",
      "  (1, 124604)\t-0.07738232325341368\n",
      "  (1, 144749)\t0.15476464650682736\n",
      "  (1, 151136)\t0.07738232325341368\n",
      "  (1, 174171)\t0.07738232325341368\n",
      "  (1, 174974)\t-0.07738232325341368\n",
      "  (1, 232512)\t0.15476464650682736\n",
      "  (1, 271872)\t0.15476464650682736\n",
      "  (1, 286878)\t-0.5416762627738958\n",
      "  (1, 289670)\t-0.07738232325341368\n",
      "  (1, 307669)\t0.07738232325341368\n",
      "  (1, 312887)\t-0.07738232325341368\n",
      "  (1, 313763)\t0.07738232325341368\n",
      "  (1, 354766)\t0.07738232325341368\n",
      "  (1, 355578)\t-0.07738232325341368\n",
      "  (1, 372702)\t0.07738232325341368\n",
      "  (1, 380136)\t-0.15476464650682736\n",
      "  (1, 399927)\t-0.07738232325341368\n",
      "  (1, 413315)\t-0.15476464650682736\n",
      "  (1, 421751)\t-0.15476464650682736\n",
      "  (1, 452780)\t-0.07738232325341368\n",
      "  :\t:\n",
      "  (4243, 952279)\t-0.01488233659121359\n",
      "  (4243, 953107)\t0.01488233659121359\n",
      "  (4243, 958756)\t-0.01488233659121359\n",
      "  (4243, 958992)\t-0.01488233659121359\n",
      "  (4243, 963256)\t-0.01488233659121359\n",
      "  (4243, 963865)\t-0.01488233659121359\n",
      "  (4243, 974501)\t0.01488233659121359\n",
      "  (4243, 975215)\t0.01488233659121359\n",
      "  (4243, 982957)\t0.07441168295606795\n",
      "  (4243, 992878)\t0.01488233659121359\n",
      "  (4243, 993015)\t0.01488233659121359\n",
      "  (4243, 994433)\t0.07441168295606795\n",
      "  (4243, 1004174)\t0.01488233659121359\n",
      "  (4243, 1004879)\t-0.01488233659121359\n",
      "  (4243, 1005723)\t-0.01488233659121359\n",
      "  (4243, 1009763)\t0.02976467318242718\n",
      "  (4243, 1010115)\t-0.01488233659121359\n",
      "  (4243, 1017691)\t-0.01488233659121359\n",
      "  (4243, 1026684)\t-0.01488233659121359\n",
      "  (4243, 1027460)\t-0.01488233659121359\n",
      "  (4243, 1032344)\t-0.01488233659121359\n",
      "  (4243, 1034375)\t-0.11905869272970872\n",
      "  (4243, 1038430)\t0.01488233659121359\n",
      "  (4243, 1039483)\t-0.01488233659121359\n",
      "  (4243, 1044795)\t0.02976467318242718\n"
     ]
    }
   ],
   "source": [
    "Hashing_vectorizer = HashingVectorizer()\n",
    "Hashin_train = Hashing_vectorizer.fit_transform(X_train)\n",
    "print(Hashin_train)\n",
    "Hashin_test = Hashing_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941f9ae6-123b-485b-8b36-dd30c10679e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4244, 1048576)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashin_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33dc481-52ac-422c-a8e4-a872699cdbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "print(Hashin_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283f6774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1048576\n"
     ]
    }
   ],
   "source": [
    "num_features = Hashing_vectorizer.n_features\n",
    "print(\"Number of features:\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ab8035-e5d1-4278-ada9-3c7e05a81424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2091, 1048576)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashin_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91747204-55b1-4c51-9e83-556726807b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4244, 1048576)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hashin_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61cc1b8-f2f9-4c53-b00b-64adb8fb07cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.69      0.94      0.80      1008\n",
      "        REAL       0.92      0.61      0.73      1083\n",
      "\n",
      "    accuracy                           0.77      2091\n",
      "   macro avg       0.81      0.78      0.77      2091\n",
      "weighted avg       0.81      0.77      0.76      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier_BNB = BernoulliNB()\n",
    "classifier_BNB.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_BNB.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "Final_pred = classifier_BNB.predict(Hashin_train[0])\n",
    "print(Final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff6cef9-56e2-4cea-a49b-ea1f0e6cc809",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplementNB\n\u001b[0;32m      3\u001b[0m classifier_CNB \u001b[38;5;241m=\u001b[39mComplementNB()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mclassifier_CNB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHashin_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m classifier_CNB\u001b[38;5;241m.\u001b[39mpredict(Hashin_test)\n\u001b[0;32m      6\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:772\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    770\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:1040\u001b[0m, in \u001b[0;36mComplementNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplementNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\utils\\validation.py:1489\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "# THIS IS NOT WORKING FOR COMPLEMENT NAIVE BAYES\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "classifier_CNB =ComplementNB()\n",
    "classifier_CNB.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_CNB.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_CNB.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce3cef0-51bc-4276-8e35-3b67b0fbf9a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultinomialNB\n\u001b[0;32m      3\u001b[0m classifier_MNB \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mclassifier_MNB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHashin_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m classifier_MNB\u001b[38;5;241m.\u001b[39mpredict(Hashin_test)\n\u001b[0;32m      6\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:772\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    770\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:894\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    893\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 894\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\utils\\validation.py:1489\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "# THIS IS NOT WORKING FOR MUTINOMIAL NAIVE BAYES\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_MNB = MultinomialNB()\n",
    "classifier_MNB.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_MNB.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "Final_pred = classifier_MNB.predict(Hashin_train[0])\n",
    "print(Final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65591036-8c7a-4bb9-bc6e-fb4715ab494d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalNB\n\u001b[0;32m      3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHashin_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(Hashin_test)\n\u001b[0;32m      6\u001b[0m score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:1391\u001b[0m, in \u001b[0;36mCategoricalNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\naive_bayes.py:1449\u001b[0m, in \u001b[0;36mCategoricalNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 1449\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1452\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategoricalNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\utils\\validation.py:881\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    880\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 881\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\project-1\\Lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    529\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m     )\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "# THIS IS NOT WORKING FOR CATEGORICAL NAIVE BAYES\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "classifier = CategoricalNB()\n",
    "classifier.fit(Hashin_train, y_train)\n",
    "y_pred = classifier.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c75d0ab-0010-4959-8255-132311b5a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.74      0.79      0.77      1008\n",
      "        REAL       0.79      0.75      0.77      1083\n",
      "\n",
      "    accuracy                           0.77      2091\n",
      "   macro avg       0.77      0.77      0.77      2091\n",
      "weighted avg       0.77      0.77      0.77      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier_KNC = KNeighborsClassifier(n_neighbors = 7, metric = 'minkowski', p = 2)\n",
    "classifier_KNC.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_KNC.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_KNC.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb8cf314-fbe2-4b25-b2f9-543d55fdfc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.86      0.89      0.87      1008\n",
      "        REAL       0.90      0.86      0.88      1083\n",
      "\n",
      "    accuracy                           0.88      2091\n",
      "   macro avg       0.88      0.88      0.88      2091\n",
      "weighted avg       0.88      0.88      0.88      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_LR =LogisticRegression(random_state=0)\n",
    "classifier_LR.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_LR.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_LR.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f404fb1-2031-44ba-a5ac-cf953c58a955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.89      0.94      0.91      1008\n",
      "        REAL       0.94      0.89      0.91      1083\n",
      "\n",
      "    accuracy                           0.91      2091\n",
      "   macro avg       0.91      0.91      0.91      2091\n",
      "weighted avg       0.91      0.91      0.91      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_SVC = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier_SVC.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_SVC.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_SVC.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5af4ca0d-fc28-482a-8cd1-7c1dbdbb78ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.88      0.92      0.90      1008\n",
      "        REAL       0.92      0.88      0.90      1083\n",
      "\n",
      "    accuracy                           0.90      2091\n",
      "   macro avg       0.90      0.90      0.90      2091\n",
      "weighted avg       0.90      0.90      0.90      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_SVCL = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier_SVCL.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_SVCL.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_SVCL.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c47097a-e515-4b9d-b7bc-226ee01f1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.78      0.80      0.79      1008\n",
      "        REAL       0.81      0.79      0.80      1083\n",
      "\n",
      "    accuracy                           0.79      2091\n",
      "   macro avg       0.79      0.79      0.79      2091\n",
      "weighted avg       0.79      0.79      0.79      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_DT = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier_DT.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_DT.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_DT.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c3a5eda-b636-4fe5-94a7-942ec819be82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.73      0.87      0.79      1008\n",
      "        REAL       0.86      0.69      0.77      1083\n",
      "\n",
      "    accuracy                           0.78      2091\n",
      "   macro avg       0.79      0.78      0.78      2091\n",
      "weighted avg       0.79      0.78      0.78      2091\n",
      "\n",
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier_RF.fit(Hashin_train, y_train)\n",
    "y_pred = classifier_RF.predict(Hashin_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.2f\" % score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report = classification_report(y_test, y_pred)              \n",
    "print(clf_report)\n",
    "# Final prediction \n",
    "final_pred = classifier_RF.predict(Hashin_train[0])\n",
    "print(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
